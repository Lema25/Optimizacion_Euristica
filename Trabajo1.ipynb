{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 1: optimización numérica"
      ],
      "metadata": {
        "id": "VBZhfnv_p1a7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Escoja dos funciones de prueba\n",
        "2. Optimice las funciones en dos y tres dimensiones usando un método de descenso por gradiente con condición inicial aleatoria\n",
        "3. Optimice las funciones en dos y tres dimensiones usando: algoritmos evolutivos, optimización de partículas y evolución diferencial\n",
        "4. Represente con un gif animado o un video el proceso de optimización de descenso por gradiente y el proceso usando el método heurístico.\n"
      ],
      "metadata": {
        "id": "NGf0mMp9pyyb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funciones mencionadas"
      ],
      "metadata": {
        "id": "xPMsth_gp8uy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRiHXSs6pjnE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Función de Rosenbrock\n",
        "def rosenbrock(x, y):\n",
        "    return (1 - x)**2 + 100 * (y - x**2)**2\n",
        "\n",
        "# Función de Rastrigin\n",
        "def rastrigin(*args):\n",
        "    A = 10\n",
        "    return A * len(args) + np.sum([(x**2 - A * np.cos(2 * np.pi * x)) for x in args])\n",
        "\n",
        "# Función de Schwefel\n",
        "def schwefel(*args):\n",
        "    return -np.sum([x * np.sin(np.sqrt(np.abs(x))) for x in args])\n",
        "\n",
        "# Función de Griewank\n",
        "def griewank(*args):\n",
        "    return 1 + (1/4000) * np.sum([x**2 for x in args]) - np.prod([np.cos(x / np.sqrt(i+1)) for i, x in enumerate(args)])\n",
        "\n",
        "# Función de Goldstein-Price\n",
        "def goldstein_price(x, y):\n",
        "    return ((1 + (x + y + 1)**2 * (19 - 14*x + 3*x**2 - 14*y + 6*x*y + 3*y**2)) *\n",
        "            (30 + (2*x - 3*y)**2 * (18 - 32*x + 12*x**2 + 48*y - 36*x*y + 27*y**2)))\n",
        "\n",
        "# Función de las seis jorobas de camello (no proporcionada)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Punto 1.\n",
        "Se escogen las funciones:\n",
        "- Rosenbrock\n",
        "- Rastrigin"
      ],
      "metadata": {
        "id": "PWB_ifA1p7xT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Punto 2.\n",
        "Optimice las funciones en dos y tres dimensiones usando un método de descenso por gradiente con condición inicial aleatoria"
      ],
      "metadata": {
        "id": "kGL_eN4mqXdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## PRUEBA (si se quiere se puede cambiar)\n",
        "\n",
        "import scipy.optimize as opt\n",
        "\n",
        "# Descenso por gradiente en dos dimensiones\n",
        "def gradient_descent_2d(func):\n",
        "    initial_guess = np.random.rand(2) * 10\n",
        "    result = opt.minimize(func, initial_guess, method='BFGS')\n",
        "    return result.x, result.fun\n",
        "\n",
        "# Descenso por gradiente en tres dimensiones\n",
        "def gradient_descent_3d(func):\n",
        "    initial_guess = np.random.rand(3) * 10\n",
        "    result = opt.minimize(func, initial_guess, method='BFGS')\n",
        "    return result.x, result.fun\n"
      ],
      "metadata": {
        "id": "X2q5lctzq3DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Punto 3.\n",
        "Optimice las funciones en dos y tres dimensiones usando: algoritmos evolutivos, optimización de partículas y evolución diferencial"
      ],
      "metadata": {
        "id": "mYdDyi8rq9Zc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Punto 4.\n",
        "Represente con un gif animado o un video el proceso de optimización de descenso por gradiente y el proceso usando el método heurístico."
      ],
      "metadata": {
        "id": "d6bdRZsPrEEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 2: optimización combinatoria\n",
        "Un vendedor debe hacer un recorrido por las siguientes ciudades de Colombia en su carro (no necesariamente en este orden):\n",
        "- Palmira\n",
        "- Pasto\n",
        "- Tuluá\n",
        "- Bogota\n",
        "- Pereira\n",
        "- Armenia\n",
        "- Manizales\n",
        "- Valledupar\n",
        "- Montería\n",
        "- Soledad\n",
        "- Cartagena\n",
        "- Barranquilla\n",
        "- Medellín\n",
        "- Bucaramanga\n",
        "- Cúcuta\n",
        "\n",
        "Utilice colonias de hormigas y algoritmos genéticos para encontrar el orden óptimo. El costo de desplazamiento entre ciudades es la suma del valor de la hora del vendedor (es un parámetro que debe estudiarse), el costo de los peajes y el costo del combustible. Cada equipo debe definir en qué carro hace el recorrido el vendedor y de allí extraer el costo del combustible.\n",
        "\n",
        "Adicionalmente represente con un gif animado o un video cómo se comporta la mejor solución usando un gráfico del recorrido en el mapa de Colombia.\n"
      ],
      "metadata": {
        "id": "ZlSshFpkqlw0"
      }
    }
  ]
}